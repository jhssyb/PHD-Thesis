\chapter*{Conclusion \& Perspectives}

% Quick summary

This thesis work proposes some methodological improvements related to Uncertainty Quantification (UQ). Apart from the novelty of these methods, they proved to be useful in various costly numerical experiments.

% First part: literature
The first part of the document reviews the literature on various aspects of UQ. The reader is walked through all the steps required to perform a UQ study in a costly numerical environment: from the definition of a Design of Experiments (DoE) to construct a surrogate model, to the use of this surrogate to compute statistics and ultimately visualize the results. The current advances and limitations of DoE are presented in~\cref{sec:doe}. OLHS and \emph{Sobol'} sequences are both considered as best practice although they exhibit some limitations such as the iterative properties and the randomization, respectively. Using this sample, one can perform a UQ analysis with methods detailed in~\cref{sec:uq}. Global Sensitivity Analysis (SA) is recommended but some efforts are still needed toward making this approach used over local SA. Looking at the method themselves, variance-based SA is still predominant but moment-based methods appear as good complement in a study. In a costly numerical environment, it is not tractable to directly perform a UQ and the usage of a surrogate model comes as a solution. \Cref{sec:surrogate} exposes two of the most used methods: Gaussian Process (GP) and Polynomial Chaos (PC). Finally, \cref{sec:visu} introduces the problem of visualizing the uncertainties. This is a fairly new field with only a limited corpus of study. There is currently no clear recommendations about how to visualize uncertainties. From this review, \cref{chap:questions} details the three questions which this thesis aims to answer:
\begin{itemize}
\item \emph{How to construct a DoE in a high-dimensional parameter space?}
\item \emph{How to resample a DoE by considering the QoI of already sampled experiments?}
\item \emph{How to visualize uncertainties in high-dimensional cases?}
\end{itemize}

% Second part: novel methods
The following part seeks to answer these questions. It begins with \cref{chap:dissemination} outlining all the scientific contributions of this thesis. A new UQ tool is presented in~\cref{chap:batman}: Batman. Batman is an open-source Python library dedicated to UQ which has been developed during this thesis. It is based on state-of-the-art statistical libraries, such as OpenTURNS, and it allows to easily perform an uncertainty analysis. All further methodological developments of this work have been consolidated through this tool. \Cref{chap:doe} presents a new iterative and versatile sampling method named KDOE. It relies on a Kernel Density Estimation (KDE) that serves as an exclusion field which allows constraining the samples not to be too close to each other. This procedure is used to iteratively fill the parameter space uniformly. It is shown that this method provides good space filling properties, especially for high-dimensional cases. On the other hand, \cref{chap:resample} answers the resampling problematic. Two novel methods based on both the Leave-One-Out (LOO) error and the variance of the surrogate model constructed by GP are presented: LOO-$\sigma$ and LOO-\emph{Sobol'}. It is shown that an improvement of the quality (over classical methods) of the surrogate model is guaranteed in high-dimensional cases. Lastly, \cref{chap:visu} introduces novel visualization strategies to visualize uncertainty. The methods are designed to help UQ practitioners by allowing the visualization of both input parameters space and  Quantity of Interest (QoI) on the same canvas by means of a 3-dimensional version of the Kiviat plot (also called spider plot). In case of functional output data, the use of sound is proposed to convey this information. The functional data is analysed using the Highest Density Region (HDR) technique, and distance from the most probable output is mapped through sound.
 
% Third part: cases
These methods are applied on various complex configurations in the last part. First of all, \cref{chap:mascaret} compares GP and PC in a hydraulic context with the 1-dimensional code: MASCARET. Both surrogate showed their ability to correctly substitute the simulator with a low number of numerical simulations. \Cref{chap:ls89} illustrates the benefits of the novel resampling methods on a configuration known in the literature to be difficult to reproduce: the aerothermal flow around the LS89 blade cascade. It is reminded that this is the first uncertainty quantification study performed using Large Eddy Simulation (LES). The code AVBP was used. The difficulty to correctly predict the flow features even for such a high-fidelity simulation, points towards the uncertainty of the boundary conditions. The turbulence intensity and the angle of attack are known to affect the aerothermal flow. This quantity is of great interest for industrial partners to determine the life-cycle of the turbine components. The study allowed to find a spatial sensitivity of the flow to the input parameters. Following, \cref{chap:swirler} presents the use of HDR in order to reduce the dimensionality of the input parameter space for a complex case: a swirler geometry. Using LES and Adaptative Mesh Refinements (AMR) the physic is captured with precision allowing assessing manufacturing dispersion coming from Additive Manufacturing (AM). This study allowed to find that the manufacturing tolerances could be reduced as the impact of additive manufacturing on the QoI was controlled. In~\cref{chap:optim}, the whole toolchain is used to perform a global optimization of the geometry of a heat exchanger---consisting in a ribbed tube. The Efficient Global Optimization (EGO) method was used to lower the computational cost of the study. The obtained surrogate model was then used to perform a UQ analysis. One of the main conclusions from this analysis is that the interaction effect between the pitch of the ribs and the emptiness ratio between the ribs was important. Finally, \cref{chap:psaap} briefly introduces a work in progress where the new sampling method is being used.

% Perspectives

% Models
The perspectives of this work are numerous. I am presenting them under three subsections: \emph{(i)} surrogate models, \emph{(ii)} uncertainty tools and \emph{(iii)} visualization.

\begin{itemize}
\item \emph{Surrogate models,}\hfill\\
As outlined, lots of work has already been devoted to the definition of surrogate models and (re)sampling strategies. The cost of this construction of a surrogate can be address using multifidelity approach. Although an extensive litterature exists, novel approaches using deep learning appeared in~\cite{raissi2016}. The optimization of weights is a key step in deep learning algorithms. During the past years, there has been an incentive toward Bayesian optimization to solve this problem. But deep learning make use of large dataset which is a concern with Gaussian Process. Some effort are being done to improve the scalability~\cite{Wilson2015}. A novel interest in Bayesian model is foreseen, not only on an applicative point-of-view but also on more theoretical aspects. Another challenge is to take into account bifurcations in the physics. A bifurcation is a qualitative change of the behaviour of a system resulting from a small smooth change (contrary to an impulsion or Dirac) made to the parameter values. The identification of classes in the input space that lead to bifurcations in the output space can be achieved by expert knowledge or with  machine learning algorithms as proposed in~\cite{Dupuis2018}.

\item \emph{Uncertainty tools,}\hfill\\
Concerning the statistical tools to assess uncertainties, from the literature review it was shown that variance based methods have become a standard. Some improvements are still possible---as shown by~\cite{Saltelli2017} where the algorithm requires less samples to converge. More work is expected concerning moment-based indices. There are a lot of metrics that can be used to discriminate the conditional and unconditional density functions. There is a wide range of mature solutions available and the challenge, as outlined in~\cite{Saltelli2019}, is toward educating people to use them. Going further, the whole community would benefit from common and updated guidelines on how to handle uncertainties. This is one of the goal of the \emph{COST action} proposal: \emph{Model Auditing and Sensitivity Analysis}.

\item \emph{Visualization,}\hfill\\
As for the visualization of uncertainty, and more generally the way to convey it in a useful way, it is still an open question. The uncertainty community is lacking interest on the matter as opposed to the \emph{data visualization} community. Interesting work around uncertainty are being published but a link between the two community is still required. Linking uncertainty visualization with deep learning is even more challenging due to the curse-of-dimensionality.

\end{itemize}


% Impact

This work has proven the feasibility of UQ in a LES context and more generally in a high computational environment. Distributing Batman openly, and thus all the novelty of this thesis work, has allowed a multitude of international collaborations with both institutional and industrial partners. On a methodological aspect, this work proposes new directions to explore. The treatment of uncertainties has become an important engineering and societal preoccupation. This thesis paves the way, not to a less uncertain world, but to a population more aware and empowered with uncertainty.








